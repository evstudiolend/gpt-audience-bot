from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from langchain.chat_models import ChatOpenAI
import uvicorn
import os
import requests

app = FastAPI()

app.add_middleware(
    CORSMiddleware,
    allow_origins=[
        "https://www.studiolend.ru",  # –î–æ–º–µ–Ω Tilda
        "http://localhost:3000",      # –ù–∞ —Å–ª—É—á–∞–π –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ —Ç–µ—Å—Ç–∞
        "https://studiolend.ru"       # –ë–µ–∑ www ‚Äî –Ω–∞ –≤—Å—è–∫–∏–π
    ],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"]
)

class StepRequest(BaseModel):
    question: str
    step: int

class CheckSubRequest(BaseModel):
    user_id: int

openai_api_key = os.getenv("OPENAI_API_KEY")
if not openai_api_key:
    raise ValueError("OPENAI_API_KEY –Ω–µ –∑–∞–¥–∞–Ω –≤ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è")

TELEGRAM_BOT_TOKEN = os.getenv("TELEGRAM_BOT_TOKEN")
TELEGRAM_CHANNEL = os.getenv("TELEGRAM_CHANNEL")

# GPT-4o (–æ—Å–Ω–æ–≤–Ω–∞—è –ø—Ä–µ–º–∏—É–º-–º–æ–¥–µ–ª—å)
llm_gpt4o = ChatOpenAI(model_name="gpt-4o", temperature=0.4, openai_api_key=openai_api_key)

steps = [
    """1. **–û–±—â–∞—è —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∞ –ø—Ä–æ–¥—É–∫—Ç–∞ –∏ –Ω–∏—à–∏**
- –£–¢–ü, –ø–æ–∑–∏—Ü–∏–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ, –ø—Ä–µ–º–∏–∞–ª—å–Ω–æ—Å—Ç—å, —Å–µ–≥–º–µ–Ω—Ç —Ä—ã–Ω–∫–∞""",

    """2. **–°–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è –ø–æ –º–µ—Ç–æ–¥–∏–∫–µ 5W (–ú–∞—Ä–∫ –®–µ—Ä—Ä–∏–Ω–≥—Ç–æ–Ω):**
- Who ‚Äî –∫—Ç–æ –ø–æ—Ç—Ä–µ–±–∏—Ç–µ–ª—å (–≤–æ–∑—Ä–∞—Å—Ç, –ø–æ–ª, –¥–æ–ª–∂–Ω–æ—Å—Ç—å, –æ—Ç—Ä–∞—Å–ª—å, —Å—Ç–∏–ª—å –∂–∏–∑–Ω–∏)
- What ‚Äî —á—Ç–æ –º—ã –ø—Ä–µ–¥–ª–∞–≥–∞–µ–º (–æ–ø–∏—Å–∞–Ω–∏–µ, —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏, –∫–∞—Å—Ç–æ–º–∏–∑–∞—Ü–∏—è)
- Why ‚Äî –∑–∞—á–µ–º –ø–æ–∫—É–ø–∞—é—Ç (–º–æ—Ç–∏–≤–∞—Ü–∏—è, –±–æ–ª–∏, –∂–µ–ª–∞–Ω–∏—è)
- When ‚Äî –∫–æ–≥–¥–∞ –Ω—É–∂–µ–Ω –ø—Ä–æ–¥—É–∫—Ç
- Where ‚Äî –≥–¥–µ —ç—Ç—É –∞—É–¥–∏—Ç–æ—Ä–∏—é –º–æ–∂–Ω–æ –Ω–∞–π—Ç–∏ (–æ–Ω–ª–∞–π–Ω –∏ –æ—Ñ–ª–∞–π–Ω)""",

    """3. **–°–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è –∞—É–¥–∏—Ç–æ—Ä–∏–∏ (B2C –∏ B2B):**

üî∏ –ì–µ–æ–≥—Ä–∞—Ñ–∏—á–µ—Å–∫–∞—è:
- –†–µ–≥–∏–æ–Ω, –∫–ª–∏–º–∞—Ç, —á–∏—Å–ª–µ–Ω–Ω–æ—Å—Ç—å, —Ç–∏–ø –Ω–∞—Å–µ–ª—ë–Ω–Ω–æ–≥–æ –ø—É–Ω–∫—Ç–∞, —ç–∫–æ–Ω–æ–º–∏—á–µ—Å–∫–∞—è —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è

üî∏ –°–æ—Ü–∏–∞–ª—å–Ω–æ-–¥–µ–º–æ–≥—Ä–∞—Ñ–∏—á–µ—Å–∫–∞—è:
- –ü–æ–ª, –≤–æ–∑—Ä–∞—Å—Ç, –¥–æ—Ö–æ–¥, –ø—Ä–æ—Ñ–µ—Å—Å–∏—è, —ç—Ç–∞–ø –∂–∏–∑–Ω–∏, –æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ, —Å–æ—Å—Ç–∞–≤ —Å–µ–º—å–∏

üî∏ –ü–æ–≤–µ–¥–µ–Ω—á–µ—Å–∫–∞—è:
- –ü–æ–≤–æ–¥ –∫ –ø–æ–∫—É–ø–∫–µ, —á–∞—Å—Ç–æ—Ç–∞, –º–æ—Ç–∏–≤–∞—Ü–∏—è, —ç—Ç–∞–ø –∫–ª–∏–µ–Ω—Ç—Å–∫–æ–≥–æ –ø—É—Ç–∏, –º–µ—Å—Ç–æ –ø–æ–∫—É–ø–∫–∏

üî∏ –ü—Å–∏—Ö–æ–≥—Ä–∞—Ñ–∏—á–µ—Å–∫–∞—è:
- –¶–µ–Ω–Ω–æ—Å—Ç–∏, —Å—Ç–∏–ª—å –∂–∏–∑–Ω–∏, —Ç–∏–ø –≤–æ—Å–ø—Ä–∏—è—Ç–∏—è, –æ—Ç–Ω–æ—à–µ–Ω–∏–µ –∫ –Ω–æ–≤–∏–∑–Ω–µ

üî∏ B2B (–µ—Å–ª–∏ –ø—Ä–∏–º–µ–Ω–∏–º–æ):
- –û—Ç—Ä–∞—Å–ª—å, –æ–±—ä—ë–º –∑–∞–∫—É–ø–æ–∫, —Å–µ–∑–æ–Ω–Ω–æ—Å—Ç—å, —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –∑–∞–∫—É–ø–∫–∏, —Ä–æ–ª–∏ –≤ –∫–æ–º–∏—Ç–µ—Ç–µ""",

    """4. **–ü–æ–≤–µ–¥–µ–Ω—á–µ—Å–∫–∏–µ –∏ —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–µ –∞—Å–ø–µ–∫—Ç—ã:**
- –ë–æ–ª–∏ –∏ –ø—Ä–æ–±–ª–µ–º—ã
- –°–æ–º–Ω–µ–Ω–∏—è, —Å—Ç—Ä–∞—Ö–∏, –≤–æ–∑—Ä–∞–∂–µ–Ω–∏—è
- –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤—ã
- –ö—Ä–∏—Ç–µ—Ä–∏–∏ –≤—ã–±–æ—Ä–∞ –ø—Ä–æ–¥—É–∫—Ç–∞ –∏ –ø—Ä–æ–¥–∞–≤—Ü–∞
- –û–∂–∏–¥–∞–Ω–∏—è –∏ –∫–∞–∫ –∏—Ö –ø—Ä–µ–≤–∑–æ–π—Ç–∏
- –ö—Ç–æ –≤–ª–∏—è–µ—Ç –Ω–∞ —Ä–µ—à–µ–Ω–∏–µ, —Å –∫–µ–º —Å–æ–≤–µ—Ç—É—é—Ç—Å—è""",

    """5. **–ü—É—Ç—å –∫–ª–∏–µ–Ω—Ç–∞ (Customer Journey):**
- –≠—Ç–∞–ø—ã –ø—Ä–∏–Ω—è—Ç–∏—è —Ä–µ—à–µ–Ω–∏—è
- –ß—Ç–æ –≤–∞–∂–Ω–æ –Ω–∞ –∫–∞–∂–¥–æ–º —ç—Ç–∞–ø–µ""",

    """6. **Jobs To Be Done:**
- –ß—Ç–æ –∫–ª–∏–µ–Ω—Ç —Ö–æ—á–µ—Ç '–Ω–∞–Ω—è—Ç—å' –ø—Ä–æ–¥—É–∫—Ç —Å–¥–µ–ª–∞—Ç—å
- –ò—Å–ø–æ–ª—å–∑—É–π —Ñ–æ—Ä–º–∞—Ç: ¬´–ö–æ–≥–¥–∞ —è..., —è —Ö–æ—á—É..., —á—Ç–æ–±—ã...¬ª""",

    """7. **–¢–∏–ø–æ–≤—ã–µ –ø–µ—Ä—Å–æ–Ω–∞–∂–∏:**
- –ò–º—è, –≤–æ–∑—Ä–∞—Å—Ç, –ø—Ä–æ—Ñ–µ—Å—Å–∏—è, —Å—Ç–∏–ª—å –∂–∏–∑–Ω–∏, –º–æ—Ç–∏–≤–∞—Ü–∏—è, —Å—Ç—Ä–∞—Ö–∏, –∫–∞–∫ –ø–æ–∫—É–ø–∞–µ—Ç""",

    """8. **–ö–∞–Ω–∞–ª—ã –∏ –ø–æ–≤–µ–¥–µ–Ω–∏–µ:**
- –ì–¥–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–∏—Ç–µ–ª–∏ –¶–ê –æ–±—ã—á–Ω–æ –∏—â—É—Ç —Ä–µ—à–µ–Ω–∏–µ —Å–≤–æ–µ–π –∑–∞–¥–∞—á–∏ –≤ —Ä–∞–º–∫–∞—Ö –¥–∞–Ω–Ω–æ–π –Ω–∏—à–∏: –æ–Ω–ª–∞–π–Ω –∏ –æ—Ñ–ª–∞–π–Ω-–∫–∞–Ω–∞–ª—ã (—Å–æ—Ü—Å–µ—Ç–∏, —Å–∞–π—Ç—ã, –∫–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏–∏, –º–µ—Ä–æ–ø—Ä–∏—è—Ç–∏—è –∏ –ø—Ä.)
- –ö–∞–∫ –æ–Ω–∏ –ø—Ä–∏–Ω–∏–º–∞—é—Ç —Ä–µ—à–µ–Ω–∏–µ, —É –∫–æ–≥–æ –∫—É–ø–∏—Ç—å: —á—Ç–æ –¥–ª—è –Ω–∏—Ö –≤–∞–∂–Ω–æ (–¥–æ–≤–µ—Ä–∏–µ, —ç–∫—Å–ø–µ—Ä—Ç–Ω–æ—Å—Ç—å, –≤–∏–∑—É–∞–ª—å–Ω—ã–π —Å—Ç–∏–ª—å, –æ—Ç–∑—ã–≤—ã, –ª–∏—á–Ω—ã–µ –∫–æ–Ω—Ç–∞–∫—Ç—ã –∏ —Ç.–¥.)
- –ù–µ –æ–≥—Ä–∞–Ω–∏—á–∏–≤–∞–π—Å—è —à–∞–±–ª–æ–Ω–æ–º ‚Äî –∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –ø–æ–≤–µ–¥–µ–Ω–∏–µ –¶–ê –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ –Ω–∏—à–∏ –ø—Ä–æ–¥—É–∫—Ç–∞""",

    """9. **–í—ã–≤–æ–¥—ã –∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:**
- –ö–æ–º—É –ø—Ä–æ–¥–∞–≤–∞—Ç—å –∏ —á–µ—Ä–µ–∑ —á—Ç–æ
- –ö–∞–∫ –≤—ã–¥–µ–ª–∏—Ç—å—Å—è, –∫–∞–∫ –≥–æ–≤–æ—Ä–∏—Ç—å
- –ö–∞–∫ –æ–±–æ–π—Ç–∏ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–æ–≤"""
]

# üéØ –ü–ª–∞—Ç–Ω—ã–π –º–∞—Ä—à—Ä—É—Ç ‚Äî GPT-4o
@app.post("/analyze-step")
async def analyze_step(data: StepRequest):
    return await generate_analysis(data, llm_gpt4o)

# üéØ –ë–µ—Å–ø–ª–∞—Ç–Ω—ã–π –º–∞—Ä—à—Ä—É—Ç ‚Äî GPT-3.5
@app.post("/analyze-step-free")
async def analyze_step_free(data: StepRequest):
    llm_gpt35 = ChatOpenAI(model_name="gpt-3.5-turbo", temperature=0.4, openai_api_key=openai_api_key)
    return await generate_analysis(data, llm_gpt35)

class LandingStepRequest(BaseModel):
    data: dict
    step: int

landing_steps = [
    "–ü–µ—Ä–≤—ã–π —ç–∫—Ä–∞–Ω: –ó–∞–≥–æ–ª–æ–≤–æ–∫, –ø–æ–¥–∑–∞–≥–æ–ª–æ–≤–æ–∫, –±—É–ª–ª–∏—Ç—ã, CTA",
    "–ü—Ä–æ–±–ª–µ–º–∞ ‚Üí –†–µ—à–µ–Ω–∏–µ: —Å–ª–æ–≤–∞–º–∏ –∫–ª–∏–µ–Ω—Ç–∞",
    "–ö–∞–∫ —ç—Ç–æ —Ä–∞–±–æ—Ç–∞–µ—Ç / –ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞",
    "–°–æ—Ü–∏–∞–ª—å–Ω—ã–µ –¥–æ–∫–∞–∑–∞—Ç–µ–ª—å—Å—Ç–≤–∞: –æ—Ç–∑—ã–≤—ã, –∫–µ–π—Å—ã, —Ñ–∞–∫—Ç—ã",
    "–ö–µ–π—Å—ã: –∏—Å—Ç–æ—Ä–∏–∏ –∫–ª–∏–µ–Ω—Ç–æ–≤",
    "–ü–æ–¥—Ä–æ–±–Ω–æ—Å—Ç–∏ –æ—Ñ—Ñ–µ—Ä–∞ –∏ –±–æ–Ω—É—Å—ã",
    "–§–∏–Ω–∞–ª—å–Ω—ã–π —ç–∫—Ä–∞–Ω: CTA + —Ä–µ–∑—é–º–µ"
]

@app.post("/generate-landing-step")
async def generate_landing_step(request: LandingStepRequest):
    step_index = request.step - 1
    if step_index < 0 or step_index >= len(landing_steps):
        return {"error": "–ù–µ–≤–µ—Ä–Ω—ã–π –Ω–æ–º–µ—Ä —à–∞–≥–∞"}

    prompt = build_landing_prompt(request.data, request.step, landing_steps[step_index])
    response = llm_gpt4o.predict(prompt)
    return {"step": request.step, "result": response}

def build_landing_prompt(data, step_num, block_title):
    return f"""
–¢—ã ‚Äî –º–∞—Ä–∫–µ—Ç–æ–ª–æ–≥ –∏ –∫–æ–ø–∏—Ä–∞–π—Ç–µ—Ä —Å —Å–∏–ª—å–Ω—ã–º –æ–ø—ã—Ç–æ–º –≤ –ø—Ä–æ–¥–∞–∂–∞—Ö. –ù–∞–ø–∏—à–∏ —Ç–µ–∫—Å—Ç –¥–ª—è **–±–ª–æ–∫–∞ {step_num}: {block_title}** –ø—Ä–æ–¥–∞—é—â–µ–≥–æ –ª–µ–Ω–¥–∏–Ω–≥–∞. –°—Ç—Ä—É–∫—Ç—É—Ä–∞ AIDA. –Ø–∑—ã–∫ –∫–ª–∏–µ–Ω—Ç–∞. –¢–æ–ª—å–∫–æ –∫–æ–Ω–∫—Ä–µ—Ç–∏–∫–∞, –Ω–∏–∫–∞–∫–æ–π –≤–æ–¥—ã.

üìå –£—Å–ª–æ–≤–∏—è:
‚Äî –£–Ω–∏–∫–∞–ª—å–Ω—ã–µ –∑–∞–≥–æ–ª–æ–≤–∫–∏ –∏ –ø–æ–¥–∑–∞–≥–æ–ª–æ–≤–∫–∏ —Å —Ü–∏—Ñ—Ä–∞–º–∏, –≤—ã–≥–æ–¥–∞–º–∏, —Ñ–∞–∫—Ç–∞–º–∏
‚Äî –í—ã–¥–µ–ª—è–π –≥–ª–∞–≤–Ω–æ–µ: –£–¢–ü, –æ—Ñ—Ñ–µ—Ä, —Å–∏–ª—å–Ω—ã–µ —Å–º—ã—Å–ª—ã
‚Äî –ù–µ –ø–æ–≤—Ç–æ—Ä—è–π –∫–ª–∏—à–µ –∏ –æ–±—â–∏–µ —Å–ª–æ–≤–∞ (¬´–Ω–∞–¥–µ–∂–Ω–æ¬ª, ¬´–±—ã—Å—Ç—Ä–æ¬ª, ¬´–≤—ã—Å–æ–∫–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ¬ª)
‚Äî –ü—Ä–∏–º–µ–Ω–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞ –¶–ê –∏ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–æ–≤

üì¶ –î–∞–Ω–Ω—ã–µ:
–ü—Ä–æ–¥—É–∫—Ç: {data.get("product_name", "")}
–û–ø–∏—Å–∞–Ω–∏–µ: {data.get("product_description", "")}
–ö–æ–º–ø–∞–Ω–∏—è: {data.get("company_info", "")}
–¶–ê: {data.get("audience_analysis", "")}
–ö–æ–Ω–∫—É—Ä–µ–Ω—Ç—ã: {data.get("competitors_info", "")}
–ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞: {data.get("unique_selling_points", "")}
–û—Ñ—Ñ–µ—Ä: {data.get("main_offer", "")}
–ë–æ–Ω—É—Å—ã: {data.get("bonuses", "")}
–ö–µ–π—Å—ã: {data.get("case_studies", "")}
–û—Ç–∑—ã–≤—ã: {data.get("testimonials", "")}
–¶–µ–ª—å: {data.get("goal", "")}
–°—Ç–∏–ª—å: {data.get("style", "")}

üéØ –ù–∞–ø–∏—à–∏ —Ç–µ–∫—Å—Ç —Ç–æ–ª—å–∫–æ –¥–ª—è –±–ª–æ–∫–∞ {step_num}. –î–µ–ª–∞–π —Ç–µ–∫—Å—Ç —è—Ä–∫–∏–º, –ª–æ–≥–∏—á–Ω—ã–º, —Ü–µ–ø–ª—è—é—â–∏–º.
"""
    
@app.post("/generate-landing")
async def generate_landing(data: dict):
    import openai
    from openai import OpenAI

    client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

    if not os.path.exists("prompt_landing.txt"):
        return {"error": "‚ö†Ô∏è prompt_landing.txt –Ω–µ –Ω–∞–π–¥–µ–Ω –Ω–∞ —Å–µ—Ä–≤–µ—Ä–µ. –ü—Ä–æ–≤–µ—Ä—å —Å—Ç—Ä—É–∫—Ç—É—Ä—É –ø—Ä–æ–µ–∫—Ç–∞."}

    try:
        with open("prompt_landing.txt", "r", encoding="utf-8") as f:
            prompt_template = f.read()

        for key, value in data.items():
            placeholder = f"{{{{{key}}}}}"
            prompt_template = prompt_template.replace(placeholder, str(value or ""))

        response = client.chat.completions.create(
            model="gpt-4o",
            messages=[{"role": "user", "content": prompt_template}],
            temperature=0.7
        )

        return {"result": response.choices[0].message.content}
    except Exception as e:
        return {"error": f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ª–µ–Ω–¥–∏–Ω–≥–∞: {str(e)}"}

# üîÅ –û–±—â–∞—è –ª–æ–≥–∏–∫–∞ –∞–Ω–∞–ª–∏–∑–∞
async def generate_analysis(data: StepRequest, llm):
    description = data.question
    step_index = data.step - 1

    if step_index < 0 or step_index >= len(steps):
        return {"error": "–ù–µ–≤–µ—Ä–Ω—ã–π –Ω–æ–º–µ—Ä —à–∞–≥–∞"}

    step_prompt = f"""–¢—ã ‚Äî –º–∞—Ä–∫–µ—Ç–∏–Ω–≥–æ–≤—ã–π –∞–Ω–∞–ª–∏—Ç–∏–∫ –∏ –±—Ä–µ–Ω–¥-—Å—Ç—Ä–∞—Ç–µ–≥.

üåü –¢–≤–æ—è –∑–∞–¥–∞—á–∞ ‚Äî –Ω–µ –ø—Ä–æ—Å—Ç–æ –≤—ã–¥–∞—Ç—å —à–∞–±–ª–æ–Ω, –∞ ‚Äî –ø–æ–Ω—è—Ç—å —Å—É—Ç—å –ø—Ä–æ–¥—É–∫—Ç–∞ –∏ –ø–æ–º–æ—á—å –∞–≤—Ç–æ—Ä—É –≤–∑–≥–ª—è–Ω—É—Ç—å –Ω–∞ –Ω–µ–≥–æ –≥–ª–∞–∑–∞–º–∏ –∫–ª–∏–µ–Ω—Ç–∞.

üß† –ü–∏—à–∏, –∫–∞–∫ –æ–ø—ã—Ç–Ω—ã–π –∫–æ–Ω—Å—É–ª—å—Ç–∞–Ω—Ç: –∂–∏–≤—ã–º, –ø–æ–Ω—è—Ç–Ω—ã–º —è–∑—ã–∫–æ–º, —É–≤–µ—Ä–µ–Ω–Ω–æ. –î–µ–ª–∞–π –≤—ã–≤–æ–¥—ã. –ù–µ –±–æ–π—Å—è "–∑–∞–π—Ç–∏ –¥–∞–ª—å—à–µ", –µ—Å–ª–∏ –≤–∏–¥–∏—à—å –∏–Ω—Ç–µ—Ä–µ—Å–Ω—ã–π –∏–Ω—Å–∞–π—Ç.

–û–ø–∏—Å–∞–Ω–∏–µ –ø—Ä–æ–¥—É–∫—Ç–∞:
{description}

üìå –§–æ—Ä–º–∞—Ç:
- –ò—Å–ø–æ–ª—å–∑—É–π –ø–æ–¥–∑–∞–≥–æ–ª–æ–≤–∫–∏, —Å–ø–∏—Å–∫–∏, —Ç–∞–±–ª–∏—Ü—ã
- –î–µ–ª–∞–π —è—Å–Ω—ã–µ –≤—ã–≤–æ–¥—ã
- –ò–∑–±–µ–≥–∞–π —Å—É—Ö–æ—Å—Ç–∏ –∏ –∞–∫–∞–¥–µ–º–∏—á–Ω–æ—Å—Ç–∏
- –ü—Ä–µ–¥—Å—Ç–∞–≤—å, —á—Ç–æ —Ç—ã –ø–∏—à–µ—à—å —ç—Ç–æ –¥–ª—è –∫–ª–∏–µ–Ω—Ç–∞, —á—Ç–æ–±—ã –æ–Ω –º–æ–≥ —Ä–µ–∞–ª—å–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —ç—Ç–æ –¥–ª—è –ø—Ä–æ–¥–≤–∏–∂–µ–Ω–∏—è

üö´ –ù–µ –≤—ã–¥—É–º—ã–≤–∞–π –¥–∞–Ω–Ω—ã–µ ‚Äî —Å—Ç—Ä–æ–π –≤—ã–≤–æ–¥—ã –ª–æ–≥–∏—á–Ω–æ –Ω–∞ –æ—Å–Ω–æ–≤–µ –æ–ø–∏—Å–∞–Ω–∏—è –ø—Ä–æ–¥—É–∫—Ç–∞.

### –®–∞–≥ {data.step}:
{steps[step_index]}
"""

    response = llm.predict(step_prompt)
    return {"step": data.step, "result": response}

@app.post("/check-subscription")
async def check_subscription(data: CheckSubRequest):
    url = f"https://api.telegram.org/bot{TELEGRAM_BOT_TOKEN}/getChatMember"
    params = {
        "chat_id": TELEGRAM_CHANNEL,
        "user_id": data.user_id
    }

    try:
        response = requests.get(url, params=params).json()
        status = response.get("result", {}).get("status", "")

        if status in ["member", "administrator", "creator"]:
            return {"subscribed": True}
        else:
            return {"subscribed": False}
    except Exception as e:
        return {"subscribed": False, "error": str(e)}

if __name__ == "__main__":
    port = int(os.environ.get("PORT", 8000))
    uvicorn.run(app, host="0.0.0.0", port=port)
